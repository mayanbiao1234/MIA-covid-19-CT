{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from os.path import join, getsize\n",
    "\n",
    "def unzip_file(zip_src, dst_dir):\n",
    "    r = zipfile.is_zipfile(zip_src)\n",
    "    if r:     \n",
    "        fz = zipfile.ZipFile(zip_src, 'r')\n",
    "        for file in fz.namelist():\n",
    "            fz.extract(file, dst_dir)       \n",
    "    else:\n",
    "        print('This is not zip')\n",
    "zip_src = '/mnt/马总/816nojiequ_zq.zip'\n",
    "dst_dir = '/mnt/马总/'\n",
    "unzip_file(zip_src, dst_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Starting------\n",
      "{'img1': 0, 'img2': 1}\n",
      "{'img1': 0, 'img2': 1}\n",
      "2008 198776\n",
      "------Dataset initialized------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0\n",
      "           Conv2d-16             [-1, 16, 1, 1]           4,112\n",
      "             ReLU-17             [-1, 16, 1, 1]               0\n",
      "           Conv2d-18            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-19            [-1, 256, 1, 1]               0\n",
      "         SEModule-20          [-1, 256, 56, 56]               0\n",
      "             ReLU-21          [-1, 256, 56, 56]               0\n",
      "SEResNetBottleneck-22          [-1, 256, 56, 56]               0\n",
      "           Conv2d-23           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-24           [-1, 64, 56, 56]             128\n",
      "             ReLU-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-27           [-1, 64, 56, 56]             128\n",
      "             ReLU-28           [-1, 64, 56, 56]               0\n",
      "           Conv2d-29          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-30          [-1, 256, 56, 56]             512\n",
      "AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0\n",
      "           Conv2d-32             [-1, 16, 1, 1]           4,112\n",
      "             ReLU-33             [-1, 16, 1, 1]               0\n",
      "           Conv2d-34            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-35            [-1, 256, 1, 1]               0\n",
      "         SEModule-36          [-1, 256, 56, 56]               0\n",
      "             ReLU-37          [-1, 256, 56, 56]               0\n",
      "SEResNetBottleneck-38          [-1, 256, 56, 56]               0\n",
      "           Conv2d-39           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-40           [-1, 64, 56, 56]             128\n",
      "             ReLU-41           [-1, 64, 56, 56]               0\n",
      "           Conv2d-42           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-43           [-1, 64, 56, 56]             128\n",
      "             ReLU-44           [-1, 64, 56, 56]               0\n",
      "           Conv2d-45          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-46          [-1, 256, 56, 56]             512\n",
      "AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0\n",
      "           Conv2d-48             [-1, 16, 1, 1]           4,112\n",
      "             ReLU-49             [-1, 16, 1, 1]               0\n",
      "           Conv2d-50            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-51            [-1, 256, 1, 1]               0\n",
      "         SEModule-52          [-1, 256, 56, 56]               0\n",
      "             ReLU-53          [-1, 256, 56, 56]               0\n",
      "SEResNetBottleneck-54          [-1, 256, 56, 56]               0\n",
      "           Conv2d-55          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-56          [-1, 128, 28, 28]             256\n",
      "             ReLU-57          [-1, 128, 28, 28]               0\n",
      "           Conv2d-58          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-59          [-1, 128, 28, 28]             256\n",
      "             ReLU-60          [-1, 128, 28, 28]               0\n",
      "           Conv2d-61          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-62          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-63          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-64          [-1, 512, 28, 28]           1,024\n",
      "AdaptiveAvgPool2d-65            [-1, 512, 1, 1]               0\n",
      "           Conv2d-66             [-1, 32, 1, 1]          16,416\n",
      "             ReLU-67             [-1, 32, 1, 1]               0\n",
      "           Conv2d-68            [-1, 512, 1, 1]          16,896\n",
      "          Sigmoid-69            [-1, 512, 1, 1]               0\n",
      "         SEModule-70          [-1, 512, 28, 28]               0\n",
      "             ReLU-71          [-1, 512, 28, 28]               0\n",
      "SEResNetBottleneck-72          [-1, 512, 28, 28]               0\n",
      "           Conv2d-73          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-74          [-1, 128, 28, 28]             256\n",
      "             ReLU-75          [-1, 128, 28, 28]               0\n",
      "           Conv2d-76          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-77          [-1, 128, 28, 28]             256\n",
      "             ReLU-78          [-1, 128, 28, 28]               0\n",
      "           Conv2d-79          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 512, 28, 28]           1,024\n",
      "AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0\n",
      "           Conv2d-82             [-1, 32, 1, 1]          16,416\n",
      "             ReLU-83             [-1, 32, 1, 1]               0\n",
      "           Conv2d-84            [-1, 512, 1, 1]          16,896\n",
      "          Sigmoid-85            [-1, 512, 1, 1]               0\n",
      "         SEModule-86          [-1, 512, 28, 28]               0\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "SEResNetBottleneck-88          [-1, 512, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "             ReLU-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0\n",
      "           Conv2d-98             [-1, 32, 1, 1]          16,416\n",
      "             ReLU-99             [-1, 32, 1, 1]               0\n",
      "          Conv2d-100            [-1, 512, 1, 1]          16,896\n",
      "         Sigmoid-101            [-1, 512, 1, 1]               0\n",
      "        SEModule-102          [-1, 512, 28, 28]               0\n",
      "            ReLU-103          [-1, 512, 28, 28]               0\n",
      "SEResNetBottleneck-104          [-1, 512, 28, 28]               0\n",
      "          Conv2d-105          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [-1, 128, 28, 28]             256\n",
      "            ReLU-107          [-1, 128, 28, 28]               0\n",
      "          Conv2d-108          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-109          [-1, 128, 28, 28]             256\n",
      "            ReLU-110          [-1, 128, 28, 28]               0\n",
      "          Conv2d-111          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-112          [-1, 512, 28, 28]           1,024\n",
      "AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0\n",
      "          Conv2d-114             [-1, 32, 1, 1]          16,416\n",
      "            ReLU-115             [-1, 32, 1, 1]               0\n",
      "          Conv2d-116            [-1, 512, 1, 1]          16,896\n",
      "         Sigmoid-117            [-1, 512, 1, 1]               0\n",
      "        SEModule-118          [-1, 512, 28, 28]               0\n",
      "            ReLU-119          [-1, 512, 28, 28]               0\n",
      "SEResNetBottleneck-120          [-1, 512, 28, 28]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         131,072\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-129         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-130         [-1, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-131           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-132             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-133             [-1, 64, 1, 1]               0\n",
      "          Conv2d-134           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-135           [-1, 1024, 1, 1]               0\n",
      "        SEModule-136         [-1, 1024, 14, 14]               0\n",
      "            ReLU-137         [-1, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-138         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-139          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-140          [-1, 256, 14, 14]             512\n",
      "            ReLU-141          [-1, 256, 14, 14]               0\n",
      "          Conv2d-142          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-143          [-1, 256, 14, 14]             512\n",
      "            ReLU-144          [-1, 256, 14, 14]               0\n",
      "          Conv2d-145         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-146         [-1, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-148             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-149             [-1, 64, 1, 1]               0\n",
      "          Conv2d-150           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-151           [-1, 1024, 1, 1]               0\n",
      "        SEModule-152         [-1, 1024, 14, 14]               0\n",
      "            ReLU-153         [-1, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-154         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-155          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-156          [-1, 256, 14, 14]             512\n",
      "            ReLU-157          [-1, 256, 14, 14]               0\n",
      "          Conv2d-158          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-159          [-1, 256, 14, 14]             512\n",
      "            ReLU-160          [-1, 256, 14, 14]               0\n",
      "          Conv2d-161         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-162         [-1, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-163           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-164             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-165             [-1, 64, 1, 1]               0\n",
      "          Conv2d-166           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-167           [-1, 1024, 1, 1]               0\n",
      "        SEModule-168         [-1, 1024, 14, 14]               0\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-179           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-180             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-181             [-1, 64, 1, 1]               0\n",
      "          Conv2d-182           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-183           [-1, 1024, 1, 1]               0\n",
      "        SEModule-184         [-1, 1024, 14, 14]               0\n",
      "            ReLU-185         [-1, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-186         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-187          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-188          [-1, 256, 14, 14]             512\n",
      "            ReLU-189          [-1, 256, 14, 14]               0\n",
      "          Conv2d-190          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-191          [-1, 256, 14, 14]             512\n",
      "            ReLU-192          [-1, 256, 14, 14]               0\n",
      "          Conv2d-193         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-194         [-1, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-195           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-196             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-197             [-1, 64, 1, 1]               0\n",
      "          Conv2d-198           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-199           [-1, 1024, 1, 1]               0\n",
      "        SEModule-200         [-1, 1024, 14, 14]               0\n",
      "            ReLU-201         [-1, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-202         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-203          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-204          [-1, 256, 14, 14]             512\n",
      "            ReLU-205          [-1, 256, 14, 14]               0\n",
      "          Conv2d-206          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-207          [-1, 256, 14, 14]             512\n",
      "            ReLU-208          [-1, 256, 14, 14]               0\n",
      "          Conv2d-209         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-210         [-1, 1024, 14, 14]           2,048\n",
      "AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-212             [-1, 64, 1, 1]          65,600\n",
      "            ReLU-213             [-1, 64, 1, 1]               0\n",
      "          Conv2d-214           [-1, 1024, 1, 1]          66,560\n",
      "         Sigmoid-215           [-1, 1024, 1, 1]               0\n",
      "        SEModule-216         [-1, 1024, 14, 14]               0\n",
      "            ReLU-217         [-1, 1024, 14, 14]               0\n",
      "SEResNetBottleneck-218         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-219            [-1, 512, 7, 7]         524,288\n",
      "     BatchNorm2d-220            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-221            [-1, 512, 7, 7]               0\n",
      "          Conv2d-222            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-223            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-224            [-1, 512, 7, 7]               0\n",
      "          Conv2d-225           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-226           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-227           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-228           [-1, 2048, 7, 7]           4,096\n",
      "AdaptiveAvgPool2d-229           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-230            [-1, 128, 1, 1]         262,272\n",
      "            ReLU-231            [-1, 128, 1, 1]               0\n",
      "          Conv2d-232           [-1, 2048, 1, 1]         264,192\n",
      "         Sigmoid-233           [-1, 2048, 1, 1]               0\n",
      "        SEModule-234           [-1, 2048, 7, 7]               0\n",
      "            ReLU-235           [-1, 2048, 7, 7]               0\n",
      "SEResNetBottleneck-236           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-237            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-238            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-239            [-1, 512, 7, 7]               0\n",
      "          Conv2d-240            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-241            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-242            [-1, 512, 7, 7]               0\n",
      "          Conv2d-243           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-244           [-1, 2048, 7, 7]           4,096\n",
      "AdaptiveAvgPool2d-245           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-246            [-1, 128, 1, 1]         262,272\n",
      "            ReLU-247            [-1, 128, 1, 1]               0\n",
      "          Conv2d-248           [-1, 2048, 1, 1]         264,192\n",
      "         Sigmoid-249           [-1, 2048, 1, 1]               0\n",
      "        SEModule-250           [-1, 2048, 7, 7]               0\n",
      "            ReLU-251           [-1, 2048, 7, 7]               0\n",
      "SEResNetBottleneck-252           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-253            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-254            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-255            [-1, 512, 7, 7]               0\n",
      "          Conv2d-256            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-257            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-258            [-1, 512, 7, 7]               0\n",
      "          Conv2d-259           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-260           [-1, 2048, 7, 7]           4,096\n",
      "AdaptiveAvgPool2d-261           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-262            [-1, 128, 1, 1]         262,272\n",
      "            ReLU-263            [-1, 128, 1, 1]               0\n",
      "          Conv2d-264           [-1, 2048, 1, 1]         264,192\n",
      "         Sigmoid-265           [-1, 2048, 1, 1]               0\n",
      "        SEModule-266           [-1, 2048, 7, 7]               0\n",
      "            ReLU-267           [-1, 2048, 7, 7]               0\n",
      "SEResNetBottleneck-268           [-1, 2048, 7, 7]               0\n",
      "       AvgPool2d-269           [-1, 2048, 1, 1]               0\n",
      "          Linear-270                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 28,088,024\n",
      "Trainable params: 28,088,024\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 316.97\n",
      "Params size (MB): 107.15\n",
      "Estimated Total Size (MB): 424.69\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6212it [1:10:29,  1.47it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.1067 Accuracy 179470/198776 (90%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:29,  2.14it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.0784 Accuracy 1874/2008 (93%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6212it [1:00:38,  1.71it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 0.1186 Accuracy 191096/198776 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:30,  2.05it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.0956 Accuracy 1956/2008 (97%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6212it [1:10:31,  1.47it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 0.0007 Accuracy 195046/198776 (98%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:34,  1.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.0140 Accuracy 1970/2008 (98%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6212it [1:04:12,  1.61it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 0.1260 Accuracy 196246/198776 (99%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:35,  1.75it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.0096 Accuracy 1972/2008 (98%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6212it [1:05:04,  1.59it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss 0.0674 Accuracy 196776/198776 (99%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:32,  1.93it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.0058 Accuracy 1982/2008 (99%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6212it [1:03:51,  1.62it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 0.0076 Accuracy 197098/198776 (99%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:29,  2.11it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.0057 Accuracy 1983/2008 (99%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4573it [46:32,  1.74it/s]"
     ]
    }
   ],
   "source": [
    "from nets import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision import transforms,datasets,models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from tools import save_model, show_accuracy, show_loss, show_img\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import LoadData\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import pretrainedmodels\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\n",
    "LR = 0.0001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "traindataSize = 198776\n",
    "testdataSize = 2008\n",
    "\n",
    "\n",
    "# 训练和验证\n",
    "criteration = nn.CrossEntropyLoss()\n",
    "def train(model, device, dataset, optimizer, epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for i, (x, y) in tqdm(enumerate(dataset)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        #loss = nn.CrossEntropyLoss(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch {} Loss {:.4f} Accuracy {}/{} ({:.0f}%)\".format(epoch, loss, correct, traindataSize,\n",
    "                                                                 100 * correct / traindataSize))\n",
    "\n",
    "\n",
    "def vaild(model, device, dataset):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in tqdm(enumerate(dataset)):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            #loss = nn.CrossEntropyLoss(output, y)\n",
    "            loss = F.cross_entropy(output, y)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    print(\n",
    "        \"Test Loss {:.4f} Accuracy {}/{} ({:.0f}%)\".format(loss, correct, testdataSize, 100. * correct / testdataSize))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('------Starting------')\n",
    "    # 确定是否使用GPU\n",
    "\n",
    "    testloader, trainloader = LoadData(BATCH_SIZE)\n",
    "    # print(train_dataset.shape)\n",
    "    print('------Dataset initialized------')\n",
    "    #定义模型\n",
    "    #model = pretrainedmodels.senet154(num_classes=1000, pretrained=None)\n",
    "    model = pretrainedmodels.se_resnet50(num_classes=1000, pretrained=None)\n",
    "    #model = pretrainedmodels.pnasnet5large(num_classes=1001, pretrained=None)\n",
    "    #model = models.resnet34(pretrained=True)\n",
    "    #加载参数\n",
    "    #model.load_state_dict(torch.load('/mnt/马总/senet154-c7b49a05.pth'))\n",
    "    model.load_state_dict(torch.load('/mnt/马总/se_resnet50-ce0d4300.pth'))\n",
    "    #model.load_state_dict(torch.load('/mnt/马总/pnasnet5large-bf079911.pth'))\n",
    "    #增加全连接层\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(512,2)\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    summary(model,(3,224,224))\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr = LR, momentum = 0.09)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(model, device, trainloader, optimizer, epoch)\n",
    "        vaild(model, device, testloader)\n",
    "    save_model(model.state_dict(),'MODELnojiequ_zq','modelsenet_99_1_10_32adam-0.00005.pt')\n",
    "\n",
    "\n",
    "    # print('------Network load successfully------')\n",
    "    # # trainset 第一个维度控制第几张图片，第二个维度控制是data还是label\n",
    "    #\n",
    "    #\n",
    "    # Loss_crossEntropy = nn.CrossEntropyLoss().to(device)\n",
    "    # print('------Loss created------')\n",
    "    #\n",
    "    # optimizer= torch.optim.RMSprop(newmodel.parameters(), lr=1e-3)\n",
    "    # train_loss_history = []\n",
    "    # train_acc_history = []\n",
    "    # test_loss_history = []\n",
    "    # test_acc_history = []\n",
    "    # MAX = 0.0\n",
    "    # tag = 0\n",
    "    # for epoch in range(EPOCHS):\n",
    "    #     epoch_train_loss = 0.0\n",
    "    #     epoch_train_acc = 0.0\n",
    "    #     epoch_test_loss = 0.0\n",
    "    #     epoch_test_acc = 0.0\n",
    "    #     # train 阶段\n",
    "    #     train_step = 0\n",
    "    #     for i, data in enumerate(trainloader):\n",
    "    #         correct = 0\n",
    "    #         train_step += 1\n",
    "    #         images, labels = data\n",
    "    #         images = images.to(device)\n",
    "    #         labels = labels.to(device)\n",
    "    #         output = newmodel(images)\n",
    "    #         # 梯度清零\n",
    "    #         optimizer.zero_grad()\n",
    "    #         # print(output)\n",
    "    #         # 加上正则化的loss\n",
    "    #         loss = Loss_crossEntropy(output, labels.to(device))\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n",
    "    #         _, predicted = torch.max(output.data, 1)\n",
    "    #         correct += (predicted == labels.to(device)).sum().item()\n",
    "    #         acc = correct / BATCH_SIZE\n",
    "    #\n",
    "    #         epoch_train_loss += loss.item()\n",
    "    #         epoch_train_acc += acc\n",
    "    #\n",
    "    #         print('Train-%d-%d, loss: %.3f, acc: %.3f' % (epoch, i, loss, acc))\n",
    "    #     train_loss_history.append(epoch_train_loss / train_step)\n",
    "    #     train_acc_history.append(epoch_train_acc / train_step)\n",
    "    #     # test 阶段\n",
    "    #     # 不跟踪梯度\n",
    "    #     with torch.no_grad():\n",
    "    #         test_step = 0\n",
    "    #         for test_data in testloader:\n",
    "    #             test_step += 1\n",
    "    #             test_correct = 0\n",
    "    #             test_images, test_labels = test_data\n",
    "    #\n",
    "    #             test_output = newmodel(test_images.to(device))\n",
    "    #             test_loss = Loss_crossEntropy(test_output, test_labels.to(device))\n",
    "    #             _, test_predicted = torch.max(test_output.data, 1)\n",
    "    #             test_correct += (test_predicted == test_labels.to(device)).sum().item()\n",
    "    #             test_acc = test_correct / 64\n",
    "    #\n",
    "    #             epoch_test_loss += test_loss.item()\n",
    "    #             epoch_test_acc += test_acc\n",
    "    #             print('Test epoch: %d, loss: %.3f, acc: %.3f' % (epoch, test_loss, test_acc))\n",
    "    #     test_loss_history.append(epoch_test_loss / test_step)\n",
    "    #     test_acc_history.append(epoch_test_acc / test_step)\n",
    "    # save_model(newmodel.state_dict(),'SE_MobileNet','model.pt')\n",
    "    # show_loss(train_loss_history, test_loss_history)\n",
    "    # show_accuracy(train_acc_history, test_acc_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果senet/1.tif [[0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0]\n",
      " [0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 1]\n",
      " [1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1]\n",
      " [1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 0]\n",
      " [1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1]\n",
      " [0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0]\n",
      " [1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0]\n",
      " [1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0]]\n",
      "预测结果senet/2.tif [[1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1]\n",
      " [1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1]\n",
      " [1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1]\n",
      " [1 0 1 1 0 0 1 1 1 0 1 0 0 1 0 1]\n",
      " [1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0]\n",
      " [1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1]\n",
      " [1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1]\n",
      " [1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1]\n",
      " [0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1]\n",
      " [1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1]\n",
      " [0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0]]\n",
      "预测结果senet/3.tif [[0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1]\n",
      " [0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1]\n",
      " [1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0]\n",
      " [0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1]\n",
      " [1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 1]\n",
      " [0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1]\n",
      " [1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1]\n",
      " [1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0]\n",
      " [0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1]\n",
      " [0 0 1 0 0 0 1 0 1 0 1 1 1 1 1 0]\n",
      " [1 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0]\n",
      " [0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1]]\n",
      "预测结果senet/4.tif [[1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1]\n",
      " [1 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1]\n",
      " [1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0]\n",
      " [1 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1]\n",
      " [1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0]\n",
      " [1 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1]\n",
      " [1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1]\n",
      " [1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1]\n",
      " [0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0]\n",
      " [1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1]\n",
      " [1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      " [0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1]\n",
      " [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
      " [1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1]\n",
      " [1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0]]\n",
      "预测结果senet/5.tif [[0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0]\n",
      " [0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1]\n",
      " [0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1]\n",
      " [0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1]\n",
      " [0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1]\n",
      " [1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1]\n",
      " [1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 0 0 0 0 1 0 1 0 1 1 1 1]\n",
      " [1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      " [0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "预测结果senet/6.tif [[0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0]\n",
      " [0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0]\n",
      " [0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0]\n",
      " [1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
      " [1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1]\n",
      " [1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0]\n",
      " [0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1]\n",
      " [0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1]\n",
      " [0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0]]\n",
      "预测结果senet/7.tif [[1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0]\n",
      " [1 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0]\n",
      " [1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1]\n",
      " [1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0]\n",
      " [1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0]\n",
      " [0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1]\n",
      " [0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1]\n",
      " [1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1]\n",
      " [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0]\n",
      " [1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0]]\n",
      "预测结果senet/8.tif [[0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1]\n",
      " [0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0]\n",
      " [0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0]\n",
      " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0]\n",
      " [1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      " [1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1]\n",
      " [0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0]\n",
      " [0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1]\n",
      " [0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      " [0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1]]\n",
      "预测结果senet/9.tif [[0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1]\n",
      " [0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0]\n",
      " [0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 1 1 0 0 0 0 1 0 1 1 1 1 0 0 0]\n",
      " [1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0]]\n",
      "预测结果senet/10.tif [[0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1]\n",
      " [0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1]\n",
      " [0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1]\n",
      " [0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1]\n",
      " [0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1]\n",
      " [0 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1]\n",
      " [0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1]\n",
      " [0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1]\n",
      " [0 1 0 0 1 1 1 0 0 0 1 1 1 0 1 1]\n",
      " [0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1]\n",
      " [0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0]]\n",
      "预测结果senet/11.tif [[1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1]\n",
      " [0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0]\n",
      " [1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0]\n",
      " [1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0]\n",
      " [0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1]\n",
      " [0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 1]\n",
      " [1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1]\n",
      " [1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1]\n",
      " [0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0]\n",
      " [0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0]]\n",
      "预测结果senet/12.tif [[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1]\n",
      " [0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1]\n",
      " [0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 1]\n",
      " [1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1]\n",
      " [1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 0]\n",
      " [0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0]\n",
      " [1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0]\n",
      " [0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0]]\n",
      "预测结果senet/13.tif [[0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1]\n",
      " [1 0 0 0 1 1 0 0 0 0 1 1 0 1 1 1]\n",
      " [1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0]\n",
      " [0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1]\n",
      " [1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1]\n",
      " [0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 1]\n",
      " [1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1]\n",
      " [1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1]\n",
      " [1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 1]\n",
      " [1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1]\n",
      " [1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0]\n",
      " [0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0]]\n",
      "预测结果senet/14.tif [[1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1]\n",
      " [0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1]\n",
      " [0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1]\n",
      " [1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0]\n",
      " [1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0]\n",
      " [1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0]\n",
      " [1 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1]\n",
      " [1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 1]\n",
      " [1 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0]\n",
      " [1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1]\n",
      " [1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1]\n",
      " [1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0]]\n",
      "预测结果senet/15.tif [[1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0]\n",
      " [1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0]\n",
      " [1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0]\n",
      " [0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0]\n",
      " [0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0]\n",
      " [0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0]\n",
      " [1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0]\n",
      " [1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0]\n",
      " [0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0]\n",
      " [1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1]\n",
      " [1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0]\n",
      " [0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1]]\n",
      "预测结果senet/16.tif [[0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1]\n",
      " [0 1 1 0 1 1 1 1 0 0 0 1 0 0 0 0]\n",
      " [0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1]\n",
      " [0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1]\n",
      " [1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0]\n",
      " [1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1]\n",
      " [0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0]\n",
      " [0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1]\n",
      " [0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0]\n",
      " [1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1]\n",
      " [0 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1]\n",
      " [1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1]]\n",
      "预测结果senet/17.tif [[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      " [1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0]\n",
      " [0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0]]\n",
      "预测结果senet/18.tif [[1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1]\n",
      " [1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1]\n",
      " [0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1]\n",
      " [0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1]\n",
      " [0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0]\n",
      " [0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1]\n",
      " [1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1]\n",
      " [1 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0]\n",
      " [1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0]\n",
      " [1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0]\n",
      " [1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0]\n",
      " [0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1]\n",
      " [1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1]]\n",
      "预测结果senet/19.tif [[1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0]\n",
      " [0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0]\n",
      " [1 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0]\n",
      " [0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "import torch\n",
    "from torchvision import transforms,datasets,models\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary\n",
    "from nets import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision import transforms,datasets,models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from tools import save_model, show_accuracy, show_loss, show_img\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import LoadData\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import pretrainedmodels\n",
    "from skimage import transform,data\n",
    "\n",
    "#model = pretrainedmodels.senet154(num_classes=1000, pretrained=None)\n",
    "model = pretrainedmodels.se_resnet50(num_classes=1000, pretrained=None)\n",
    "#model = models.resnet34(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512,2)\n",
    ")\n",
    "model.load_state_dict(torch.load('/mnt/马总/MODELnojiequenvi/modelsenet_9_1_10_32adam-0.00005.pt',map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "#  test\n",
    "# k是19个地区/文件夹\n",
    "for k in range(19):\n",
    "    # 预先产生16*16的数组，用于存放单个地区的预测结果\n",
    "    a = np.ones((16, 16))\n",
    "    for i in range(16):\n",
    "\n",
    "        for j in range(16):\n",
    "            # 读入小图\n",
    "            img_path = \"816_L2A_Val_predict/\" + str(k + 1) + \"/\" + str(i * 16 + j + 1) + \".tif\"\n",
    "\n",
    "            # 用tiff读入数据，转为numpy数组\n",
    "            # img = np.array(tiff.imread(img_path))\n",
    "            # img = torch.tensor(img)\n",
    "            # 将数组转为224*224\n",
    "            # img = transform.resize(img, (224, 224))\n",
    "            tf = transforms.Compose([\n",
    "                #lambda x: Image.open(x).convert(\"RGB\"),  # string path => image data\n",
    "                lambda x: transform.resize(np.array(tiff.imread(x)), (224, 224)),\n",
    "                #transforms.Resize((int(224 * 1.25), int(224 * 1.25))),\n",
    "                #transforms.RandomRotation(15),\n",
    "                #transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "            img = tf(img_path)\n",
    "            img = img.type(torch.FloatTensor)\n",
    "            img = np.expand_dims(img, axis=0)  # 为batch添加第四维\n",
    "            # print(img.shape)\n",
    "            img = torch.tensor(img)\n",
    "            # print(model(img))\n",
    "            # 调用模型，输出预测结果\n",
    "            label = np.argmax(model(img).detach().numpy())\n",
    "\n",
    "            if label == 0:\n",
    "                # print('有人')\n",
    "                a[i, j] = 1\n",
    "            else:\n",
    "                # print('没人')\n",
    "                a[i, j] = 0\n",
    "\n",
    "    # 讲结果转为uint8\n",
    "    a = a.astype(np.uint8)\n",
    "\n",
    "    path = '预测结果senet'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    # 保存结果\n",
    "    print(path+'/' + str(k + 1) + '.tif', a)\n",
    "    tiff.imsave(path+'/' + str(k + 1) + '.tif', a)\n",
    "    # plt.imshow(a, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "import torch\n",
    "from torchvision import transforms,datasets,models\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary\n",
    "from nets import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision import transforms,datasets,models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from tools import save_model, show_accuracy, show_loss, show_img\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import LoadData\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "#model.load_state_dict(torch.load('0.81.pth',map_location='cpu'))\n",
    "#model.load_state_dict(torch.jit.load('/mnt/马总/0.81.pth',map_location='cpu'))\n",
    "model_dir = '0.81-1.pth'\n",
    "\n",
    "dict = torch.load(model_dir)\n",
    "older_val = dict['fc.bias']\n",
    "# 修改参数名\n",
    "dict['fc.0.bias'] = dict.pop('fc.bias')\n",
    "torch.save(dict, '0.81-2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2ea43ec79a4285bc1cb1940fff30c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\". \n\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-74563ff9d9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#model = resnet34(num_classes=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel_weight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/mnt/马总/0.81/0.81.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weight_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\". \n\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\". "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#from Resnet_remote.model_building import resnet34\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "from torchvision import transforms,datasets,models\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.Resize(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "X = np.zeros((1, 800, 800, 3))\n",
    "X_input = np.zeros((256, 50, 50, 3))\n",
    "model = models.resnet34(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512,2)\n",
    ")\n",
    "#model = resnet34(num_classes=2)\n",
    "model_weight_path = \"/mnt/马总/0.81/0.81.pth\"\n",
    "model.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "path = '/mnt/马总/0.81/L2A_Val_predict'\n",
    "land_types = os.listdir(path)\n",
    "tif_out = np.zeros((256, 1)).astype(np.uint8)\n",
    "for tidx, lt in enumerate(land_types):\n",
    "    for i in range(256):\n",
    "        img = Image.open(path + '/' + lt + '/' + str(i+1) + '.tif')\n",
    "        img = data_transform(img)\n",
    "        img = torch.unsqueeze(img, dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = torch.squeeze(model(img))\n",
    "            predict = torch.softmax(output, dim=0)\n",
    "            predict_cla = torch.argmax(predict).numpy()\n",
    "            tif_out[i] = predict_cla\n",
    "    print(tif_out)\n",
    "    tif_result = tif_out.reshape(16, 16).astype(np.uint8)\n",
    "    print(tif_result)\n",
    "    io.imsave('/mnt/马总/0.81/' + lt + '.tif', tif_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pretrainedmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0e2116fc8906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpretrainedmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pretrainedmodels'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
